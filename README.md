# Deep Learning Basics

#### The basics of Deeplearning
#### Inspiration is taken from programming assignments of deeplearning.ai specialization

### 01 . Numpy Basics
- basics of numpy
- broadcasting using numpy
- time gap between non-vectorized and vectorized computations

### 02. Logistic Regression
- Classifying cat and non cat using Logistic Regression
- Logistic Regression as a simple Neural Network
- Implementation of both Forward Propagation and Backward Propagation

### 03. 2LayeredNeuralNetwork
- classifying cat and non cat using a Simple Neural Network with one Hidden Layer
- Implementation of both Forward Propagation and Backward Propagation

### 04. DeepNeuralNetwork
-  Classifying cat and non cat using a Simple Neural Network with 4 Hidden Layers
- Implementation of both Forward Propagation and Backward Propagation


### 05. Regularization
- Using Regularization Techniques to prevent Overfitting
- Techniques used :
    - L2 Regularization
    - Dropout Regularization

### 06. Initialization
- How Random Initialization affects Neural Networks
- Importance of setting Random seeds

### 07.  Gradient Checking
- Implementing Gradient Checking to check if our Gradient Descent Algorithm is working properly

### 08. Optimization Algorithms
- How different Optimization Algorithms can change the course and speed of learning
- Optimization Algorithms discussed :
    - Gradient Descent
    - Mini_Batch Gradient Descent
    - Mini_Batch Gradient Descent with Momentum
    - Adam Optimization Technique

### datasets
- the cat,non-cat datasets(both test and train)  as .h5 files
- a standardized data.mat for proper visualization of Regularization effects and Optimization Algorithms

**Each folder has a utility file which helps to import .h5 and .mat datasets**
**The utility file may or may not contain helper functions provided by deeplearning.ai**
